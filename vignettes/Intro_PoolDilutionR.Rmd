---
title: "Introduction to PoolDilutionR"
output:
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{Intro_PoolDilutionR}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
options(rmarkdown.html_vignette.check_title = FALSE)

knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# What is Pool Dilution?

Pool dilution is an isotope tracer technique wherein a biogeochemical pool is artificially enriched with its heavy isotopologue (molecules of the same chemical formula and bonding structure that differ only in their isotopic composition). After enrichment, the gross production and consumption rates of that pool can be calculated using the change in isotopic signature and absolute pool size over time. This technique can be applied to many different chemical species and was originally developed to measure soil nutrient transformations (Kirkham and Bartholomew 1954).  \
  
## PoolDilutionR (PDR)

PDR uses equations originally published in von Fischer and Hedin 2002, 10.1029/2001GB001448, with some modifications. The strength of this method is that the equations take into account the effect of isotopic fractionation (see Under the hood for more information.).  
\
   
### Worked Example  

Below we isolate one sample's worth of data from PDR's internal dataset, source Morris et al, *in prep*.  
\
```{r setup}
library(PoolDilutionR)

OneSample_dat <- subset(Morris2023, subset = id == "71")
print(OneSample_dat)

```
  
  **Key to columns**:

|    id: sample id
|    time_days: time (in days) between samples 
|    cal12CH4ml: mL's of 12C methane, calculated from incubation volume and sample ppm  
|    cal13CH4ml: mL's of 13C methane, calculated from incubation volume and sample ppm  
|    AP_obs: percent of methane that is 13C methane, 13C/(12C + 13C) * 100  
\
  
### Solving for gross rates

To solve for gross methane production and consumption for this sample, we call pdr_optimize(), which uses optim() to minimize the error in the observed vs predicted pool size and isotopic composition. Errors are weighted by a  combination of data quality and explanatory power (see cost_fuction()) and predictions are made using ap_prediction(). See Under the hood for more information.\
\

```{r Solve for P and k}

pdr_optimize(time = OneSample_dat$time_days, #time as a vector
             m = OneSample_dat$cal12CH4ml + OneSample_dat$cal13CH4ml, #total pool size
             n = OneSample_dat$cal13CH4ml,#pool size of heavy isotopologue
             P = 0.1, #inital production rate for optim()
             pool = "CH4", #indicates use of default fractionation rates of methane
             m_prec = 0.001, #instrument precision for total pool size, as standard deviation
             ap_prec = 1, #instrument precision for atom percent, as standard deviation
             include_progress = FALSE) #if all tested values are desired, change to TRUE
```
Default output shows optimized variables (here P and k), initial parameter values, as well as details of the bounds, convergence, and methods for optim(). This is a little unwieldy, so we also provide a clean version that generates a dataframe.\
  
### Clean Output
```{r OneSample Results}
pdr_optimize_tidy(time = OneSample_dat$time_days,
             m = OneSample_dat$cal12CH4ml + OneSample_dat$cal13CH4ml,
             n = OneSample_dat$cal13CH4ml,
             P = 0.1,
             pool = "CH4",
             m_prec = 0.001,
             ap_prec = 1,
             include_progress = FALSE)
```

From k, the gross consumption rate can be calculated for any pool size of interest.  
  

## Variations with pdr_optimize()
  
To demonstrate additional capabilities, we need to bring in additional sample data.  
  
```{r Multi-sample Example Input, fig.height = 5, fig.width = 7, fig.align='center'}

#create long data
AP_obs <- subset(Morris2023,  select = c("id", "AP_obs", "time_days"))
AP_obs$name <- "AP_obs"
colnames(AP_obs)[colnames(AP_obs) == "AP_obs"] = "value"

cal12CH4ml <- subset(Morris2023,  select = c("id", "cal12CH4ml", "time_days"))
cal12CH4ml$name <- "cal12CH4ml"
colnames(cal12CH4ml)[colnames(cal12CH4ml) == "cal12CH4ml"] = "value"

cal13CH4ml <- subset(Morris2023,  select = c("id", "cal13CH4ml", "time_days"))
cal13CH4ml$name <- "cal13CH4ml"
colnames(cal13CH4ml)[colnames(cal13CH4ml) == "cal13CH4ml"] = "value"

long_Morris2023 <- rbind(AP_obs, cal12CH4ml, cal13CH4ml)

library(ggplot2)
theme_set(theme_minimal() + theme(text = element_text(size = 11)))

#create facet labels
facet_labels <- c(
    AP_obs = "Atom% Observed",
    cal12CH4ml = "12C Methane (mL)",
    cal13CH4ml = "13C Methane (mL)")  

ggplot(data = long_Morris2023,
       aes(time_days, value, group = as.factor(id),
                             color = as.factor(id))) +
    scale_color_discrete("Sample ID") +
    geom_point() + geom_line() + ylab("") + xlab("\n Timestep (d)") +
    ggtitle("Example Input Data") +
    facet_wrap(~name, scales = "free_y",
                labeller = labeller(name = facet_labels)) +
    theme(axis.text.x = element_text(angle = 45, hjust = 0.75)) -> input_data
print(input_data)
```
  
Now we show a graphical summary of the results from running these samples through pdr_optimize() with the same arguments as shown for sample 71 above.  


```{r Do the thing!, echo=FALSE, message = FALSE, results='hide'}
pk_results <- list()
incdat_out <- list()
all_predictions <- list()

library(tibble)

for(i in unique(Morris2023$id)) {
    message("------------------- ", i)
    # Isolate this sample's data
    dat <- Morris2023[Morris2023$id == i,]

    
result <- pdr_optimize(time = dat$time_days,
                          m = dat$cal12CH4ml + dat$cal13CH4ml,
                          n = dat$cal13CH4ml,
                          P = 0.1,
                          pool = "CH4",
                          m_prec = 0.001,
                          ap_prec = 1,
                          include_progress = TRUE)
    
    # Save progress details separately so they don't print below
    progress_detail <- result$progress
    result$progress <- NULL

    P <- result$par["P"]
    id <- dat$id[1]
    pk_results[[i]] <- tibble(id = id,
                              P = P,
                              k = result$par["k"],
                              k0 = result$initial_par["k"],
                              convergence = result$convergence,
                              message = result$message)
    
    # Predict based on the optimized parameters
    pred <- ap_prediction(time = dat$time_days,
                          m0 = dat$cal12CH4ml[1] + dat$cal13CH4ml[1],
                          n0 = dat$cal13CH4ml[1],
                          P = P,
                          k = result$par["k"],
                          pool = "CH4")
    dat <- cbind(dat, pred)
    
    # Predict based on ALL the models that were tried
    
    x <- split(progress_detail, seq_len(nrow(progress_detail)))
    all_preds <- lapply(x, FUN = function(x) {
      y1<- data.frame(P = x$P[1],
                      k = x$k[1],
                      time = seq(min(dat$time_days), max(dat$time_days), length.out = 20))
      y2 <- ap_prediction(time = y1$time,
                          m0 = dat$cal12CH4ml[1] + dat$cal13CH4ml[1],
                          n0 = dat$cal13CH4ml[1],
                          P = x$P[1],
                          k = x$k[1],
                          pool = "CH4")
      cbind(y1, y2)
    })
    all_predictions[[i]] <- do.call(rbind, all_preds)
    all_predictions[[i]]$id <- id 
    # Calculate implied consumption (ml) based on predictions
    # Equation 4: dm/dt = P - C, so C = P - dm/dt
    total_methane <- dat$cal12CH4ml + dat$cal13CH4ml
    change_methane <- c(0, diff(total_methane))
    change_time <- c(0, diff(dat$time_days))
    dat$Pt <- P * change_time #P is ml/day
    #amount of methane produced at time (t) of this incubation, a volume in mL
    dat$Ct <- dat$Pt - change_methane
    #amount of methane consumed at time (t) of this incubation, a volume in mL

    incdat_out[[i]] <- dat
}

pk_results <- do.call(rbind, pk_results)
incdat_out <- do.call(rbind, incdat_out)
all_predictions <- do.call(rbind, all_predictions)
 
#Don't think we need these anymore
 # incdat_out %>%
 #     # compute correlation between predictions and observations
 #     group_by(id) %>%
 #     #mutate(id == as.character(id)) %>%
 #     summarise(m_cor = cor(cal12CH4ml + cal13CH4ml, mt),
 #               ap_cor = cor(AP_obs, AP_pred)) ->
 #     performance_summary
 # 
 # performance_summary %>%
 #     right_join(pk_results, by = "id") ->
 #     pk_results
 # print(pk_results)
 # 
 # pk_results %>%
 #     right_join(incdat_out, by = "id") ->
 #     incdat_out
```

### Visual Summary of Multisample Output
  
Here we see variation among six samples in the goodness of fit for final optimized P and k values (colored line) in terms of predicted isotopic signature (Atom% 13C) and pool size (Total Methane). Grey lines represent values tested on the way to the final optimized fit.  
\
```{r Future Note, include = FALSE, echo = FALSE}
#For consideration, include link here to additional supplementary materials that include code for making the plots below
```
```{r Multisample Fit APE, echo = FALSE, fig.height = 5.5, fig.width = 8.25}
# ----- Plot AP results -----
  ggplot(incdat_out, aes(time_days, AP_obs, color = as.factor(id))) +
  geom_point(aes(shape = ""), size = 4) +
  geom_line(data = all_predictions,
            aes(time, AP_pred, group = paste(id, P, k)), color = "grey", linetype = 2) +
  geom_line(aes(y = AP_pred, group = id, linetype = ""),
            linewidth = 1.5) +
  scale_linetype_manual(name = "Prediction",
                        values = "dotted") +
  scale_shape_manual(name = "Observations",
                     values = 20) +
  scale_color_discrete(guide = "none") +
  facet_wrap(~as.numeric(id), scales = "free") +
  xlab("\n Timestep \n") + ylab("\n (13C-CH4/Total CH4) x 100 \n") +
  ggtitle("\n Atom% 13C \n") + theme(legend.position = "bottom")
```
  
  Pool size predictions (total methane below) are consistently tight to observations, whereas signature fits (atom%13C) have more variation.  
  
```{r Multisample Fit Total Pool, echo = FALSE, fig.height = 5.5, fig.width = 8.25}

ggplot(incdat_out, aes(time_days, cal12CH4ml + cal13CH4ml, color = as.factor(id))) +
  geom_point(aes(shape = ""), size = 4) +
  geom_line(data = all_predictions,
            aes(time, mt, group = paste(id, P, k)), color = "grey", linetype = 2) +
  geom_line(aes(y = mt, group = id, linetype = ""),
            linewidth = 1.5) +
  scale_linetype_manual(name = "Prediction",
                        values = "dotted") +
  scale_shape_manual(name = "Observations",
                     values = 20) +
  scale_color_discrete(guide = "none") +
  facet_wrap(~as.numeric(id), scales = "free") +
  xlab("\n Timestep \n") + ylab("\n Volume (mL) \n") +
  ggtitle("\n Total Methane \n") + theme(legend.position = "bottom")
```
\
Poor fits can result from a variety of issues, from instrument error, to incorrect assumptions regarding fractionation rates. 
\

### Variable Fractionation  

The most common goal in pool dilution experiments is to estimate production
`P` and consumption `k`, but `PoolDilutionR` can be used to optimize
any or all of four parameters: `P`, `k`, `frac_P` (the isotopic fractionation
value of production), and `frac_k` (fractionation of consumption). Caution should be used in parameter selection, based on prior knowledge of the biological system.  

For example, we can tell `pdr_optimize` that the production and consumption
values are fixed (i.e., known) and ask it to optimize only the fractionation rates:

```{r}

# Sample 64 above has poor fit for atom%13C

Sample64_dat <- subset(Morris2023, subset = id == "64")

pdr_optimize_tidy(time = Sample64_dat$time_days,
                  m = Sample64_dat$cal12CH4ml + OneSample_dat$cal13CH4ml, 
                  n = Sample64_dat$cal13CH4ml,
                  P = 6,
                  k = 36,
                  params_to_optimize = c("frac_P", "frac_k"),
                  pool = "CH4",
                  m_prec = 0.001,
                  ap_prec = 1)

####
####
#Start here
####
####
#Now graph new AP and pool fit
```

(As before, we are using `pdr_optimize_tidy` for tidy data frame output.)

We can see that
* the initial value of `P` was specified
* the intial value of `k` was computed from the data, because we did not specify it
* initial values for `frac_P` and `frac_k` were looked up from the package's `pdr_fractionation` table based on the pool (here, methane)
* as requested, the optimizer only optimized `frac_P` and `frac_k`

The help page for `pdr_optimize` provides other examples of this.

### Known Production rate
  
## Under the hood.  
    
  
### Prediction  
  
Equation 9  
$$ n_t = n_0^{(-k\alpha t)}$$  
  
Equation 10  
  
***  
***  
$AP_p$?  
***  
***  
  
$$ AP_t = \frac {n_t}{m_t} + AP_p $$

Equation 11
From von Fischer and Hedin 2002 (equation 11):\
\
$$
AP_t = \frac{n_0^{-k\alpha t}}{\frac{P}{k}-(\,\frac{P}{k}-m_0)^{-kt}\,}
$$
Where:  
$AP_t$ is the predicted atom percent composition of the pool at time $t$.    
$n_0$ is the pool size of the heavy isotopologue at time zero.  
$m_0$ is the total pool size at time zero.  
$P$ is the gross production rate.  
$k$ is the first order rate constant of consumption.  
$t$ is time.  
  
and    
$$
\alpha = \frac{k_{(\,^{13}C)\,}}{k_{(\,^{12}C)\,}}
$$
\
Where:\
$k_{(\,^{13}C)\,}$ is the first-order rate constant for consumption of 13CH4\
and\
$k_{(\,^{12}C)\,}$ is the first-order rate constant for consumption of 12CH4\
\
### Cost Function  

$$E = \left(\sum_{t=1}^j\frac {AP_{obs}(t) - AP_{pred}(t)}{SD_{obs-AP}}\right) * N_{ap} + \left(\sum_{t=1}^j\frac {m_{obs}(t) - m_{pred}(t)}{SD_{obs-m}}\right) * N_{m}$$
  
### Fractionation  
  
Fractionation describes the tendency of heavier isotopes and isotopologues to resist chemical transformation, whether these be phase changes, passive (term?) chemical reactions, or enzyme-mediated. There are two major types of fractionation. Equilibrium fractionation occurs when phase changes favor the heavier isotopologue staying a lower energy state (Urey 1947, Druhan, Winnick, and Thullner 2019). A typical example would be the relative enrichment of the ocean in heavy water $H_2^{18}O$ due to preferential evaporation of light water $H_2^{16}O$. The second major type of fractionation is kinetic, and is classically associated enzyme selectivity (citation). This is what drives the distinction in $^{13}C$ signatures between C3 and C4 plants (citation).  

While our knowledge of enzyme diversity is rapidly expanding...

## Literature
